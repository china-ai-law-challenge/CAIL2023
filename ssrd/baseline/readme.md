# 事实认定基线模型

# 方法介绍
该方法将每一个案件的Case_Info拆分为文本长度为1500的片段，并且将在该片段出现的次终待证事实（Inter_result）或次终待证事实对应的证据(Evidence_link)分别组成一个指令微调数据。然后使用切片后构建出的指令微调数据集微调法律大语言模型，得到可以根据切片的Case_Info输出次终待证事实位置以及证据位置的大语言模型。在测试阶段将将测试数据集每个数据集案件依然切片为文本长度为1500的片段，通过使用微调的大语言模型得到次终待证事实的位置及其对应的证据位置，最后将每一个案件的片段分别拼接成整体的案件次终待证事实以及证据位置。并最后将每个案件的次终待证事实合并输入到没有经过微调的法律大语言模型当中得到最终的事实认定结果。

# 使用方法
该项目使用微调的[lexilaw-6b](https://github.com/CSHaitao/LexiLaw)的LexiLaw_Finetune作为基线模型。您需要先将LexiLaw项目文件以及模型参数文件放入到我们的项目文件夹中，并且使用`pip install -r requirements.txt`安装配置项目环境。然后使用dataproc中的脚本，依次按照阿拉伯数字顺序运行脚本，将比赛训练数据集加工成指令微调数据集格式, 并使用train文件夹中的脚本使用构建好的指令微调数据集微调模型。最后将微调好的大语言模型以及原始的LexiLaw_Finetune模型调用eval中的测试脚本在测试集上进行测试，得到最后的预测结果。最终得到的baseline为final_score为13.52，fact-semantic-score为47.24，fact-rouge-score为12.29，interpretability-score为0.76。比赛的最终得分以final_score为准。

# 硬件配置
该项目的微调法律大语言模型在单块A100 80G上训练，cuda版本为12.0，该方法的训练过程需要35G显存，但在推理阶段仅需要24G显存。
